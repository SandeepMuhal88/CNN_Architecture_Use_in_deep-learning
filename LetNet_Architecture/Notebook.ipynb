{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aa7ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def LeNet5(input_shape=(32,32,1), num_classes=10):\n",
    "    \"\"\"\n",
    "    Original LeNet-5 implementation with Tanh activations\n",
    "    Args:\n",
    "        input_shape: (height, width, channels)\n",
    "        num_classes: number of output classes\n",
    "    Returns:\n",
    "        Keras model\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        # Layer 1: Conv + Tanh\n",
    "        layers.Conv2D(6, (5,5), activation='tanh', input_shape=input_shape),\n",
    "        # Layer 2: AvgPool\n",
    "        layers.AveragePooling2D((2,2), strides=2),\n",
    "        \n",
    "        # Layer 3: Conv + Tanh \n",
    "        layers.Conv2D(16, (5,5), activation='tanh'),\n",
    "        # Layer 4: AvgPool\n",
    "        layers.AveragePooling2D((2,2), strides=2),\n",
    "        \n",
    "        # Flatten\n",
    "        layers.Flatten(),\n",
    "        \n",
    "        # Layer 5: Fully Connected\n",
    "        layers.Dense(120, activation='tanh'),\n",
    "        # Layer 6: Fully Connected \n",
    "        layers.Dense(84, activation='tanh'),\n",
    "        # Output\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Modern Variant with ReLU/MaxPool\n",
    "def LeNet5_Modern(input_shape=(32,32,1), num_classes=10):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(6, (5,5), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        \n",
    "        layers.Conv2D(16, (5,5), activation='relu'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(120, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(84, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
